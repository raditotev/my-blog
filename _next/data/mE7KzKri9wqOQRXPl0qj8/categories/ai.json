{"pageProps":{"category":"ai","posts":[{"id":"fine-tuning-gemma-3-model-with-mlx","title":"Fine-Tuning Google's Gemma-3-4B-IT Model with MLX_LM and Preparing It for Ollama","date":"2025-11-21T00:00:00.000Z","description":"The article is a blog post that offers a detailed, step-by-step guide to fine-tuning Google's Gemma-3-4B-IT model using MLX_LM on Apple Silicon. It covers downloading the base model from Hugging Face, training with LoRA adapters and a custom dataset, fusing the adapters, copying the tokenizer, converting the model to GGUF format for compatibility with Ollama, and setting up a Modelfile for deployment.","categories":["ai","macos"]}]},"__N_SSG":true}